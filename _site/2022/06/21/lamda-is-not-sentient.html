<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>No, LaMDA Isn't Sentient - Lara J. Martin</title>

  <!-- Edit site and author settings in `_config.yml` to make the social details your own -->

    <meta content="Lara J. Martin's Blog" property="og:site_name">
  
    <meta content="No, LaMDA Isn't Sentient - Lara J. Martin's Blog" property="og:title">
  
  
    <meta content="article" property="og:type">
  
  
    <meta content="I explain at a high level why LaMDA can't be sentient." property="og:description">
  
  
    <meta content="https://laramartin.net/2022/06/21/lamda-is-not-sentient.html" property="og:url">
  
  
    <meta content="2022-06-21T01:00:00-04:00" property="article:published_time">
    <meta content="https://laramartin.net" property="article:author">
  
  
    <meta content="https://laramartin.net/assets/img/alina-grubnyak-ZiQkhI7417A-unsplash.jpg" property="og:image">
  
  
    
  
  
    
    <meta content="Language Models" property="article:tag">
    
    <meta content="Neural Networks" property="article:tag">
    
    <meta content="Artificial General Intelligence" property="article:tag">
    
  

    <meta name="twitter:card" content="summary">
  
    <meta name="twitter:title" content="No, LaMDA Isn't Sentient - Lara J. Martin's Blog">
  
  
    <meta name="twitter:url" content="https://laramartin.net/2022/06/21/lamda-is-not-sentient.html">
  
  
    <meta name="twitter:description" content="I explain at a high level why LaMDA can't be sentient.">
  
  
    <meta name="twitter:image:src" content="https://laramartin.net/assets/img/alina-grubnyak-ZiQkhI7417A-unsplash.jpg">
  

	<meta name="description" content="I explain at a high level why LaMDA can't be sentient.">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<link rel="shortcut icon" href="https://laramartin.net/favicon.ico" type="image/x-icon">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#263959">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#263959">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#263959">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=PT+Serif:400,700|Lato:300,400,700&display=swap" rel="stylesheet">
	<!-- Font Awesome -->
	<script src="https://kit.fontawesome.com/cb53008265.js" crossorigin="anonymous"></script>
	<!-- <link href="/assets/fonts/font-awesome/css/fontawesome.css" rel="stylesheet">
	  <link href="/assets/fonts/font-awesome/css/brands.css" rel="stylesheet">
	  <link href="/assets/fonts/font-awesome/css/solid.css" rel="stylesheet">-->
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/blog.css">
	
	<script language="JavaScript" type="text/javascript" src="https://code.jquery.com/jquery-3.4.1.min.js"></script>

</head>

<body>

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href="https://laramartin.net" aria-label="Back to main website"><img src="/assets/img/lara2021-square.jpg" aria-label=Lara J. Martin, PhD"></a>
      </div>
      <div class="author-name">Lara J. Martin, PhD</div>
      <p>Assistant Professor at the University of Maryland, Baltimore County</p>
      <p>
      &mdash;
      <p>
      [<a href="https://laramartin.net" aria-label="Lara's homepage">Back to Lara's Main Site</a>]
      </p>
    </div>
  </header> <!-- End Header -->
  <footer>
    <section class="contact">
      <h3 class="contact-title">Contact me</h3>
      <ul>
        
          <li><a href="https://bsky.app/profile/laramartin.net" target="_blank"><i class="fa-brands fa-bluesky"></i></a></li>
        
        
          <li><a href="http://github.com/lara-martin" target="_blank"><i class="fa-brands fa-github"></i></a></li>
        
        
          <li><a href="https://in.linkedin.com/in/lara-j-martin" target="_blank"><i class="fa-brands fa-linkedin"></i></a></li>
        
        
          <li><a href="https://twitter.com/LangTechLara" target="_blank"><i class="fa-brands fa-twitter"></i></a></li>
        
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
      <p> &copy; Lara J. Martin, PhD</p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->
<div class="content-box clearfix">
  <article class="article-page">
  <div class="page-content">
    
    <div class="page-cover-image">
      <figure>
        <img class="page-image" src=https://laramartin.net/assets/img/alina-grubnyak-ZiQkhI7417A-unsplash.jpg alt="No, LaMDA Isn't Sentient">
        
          <figcaption>A photograph of a complex web of strings suspended in a room.</figcaption>
        
        
        <div class="attribution">by <i>Alina Grubnyak via https://unsplash.com/photos/ZiQkhI7417A</i></div>
        
      </figure>
    </div> <!-- End Page Cover Image -->
    
    <div class="wrap-content">
      <header class="header-page">
        <h1 class="page-tiimg-attributiontle">No, LaMDA Isn't Sentient</h1>
        <div class="page-date"><span>Jun 21, 2022&nbsp;&nbsp;&nbsp;&nbsp;</span>&#8226;&emsp;<span class="post-words">5 minute read</span></div>
      </header>
      <p>You might have come across <a href="https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917">an article</a> being shared by some of your friends and family on Facebook recently.
In it, the author claims to have an “interview” with an AI called LaMDA in which the AI “claims to be sentient.”
For context, I am researcher who works in artificial intelligence, natural language generation (NLG), and cognitive modeling who has directly worked with LaMDA (paper published soon), among other similar language models (LMs). And I can say with 100% certainty that LaMDA is not sentient.</p>

<p><strong>Can it say things that make it seem like it has metacognition—the ability to think about thinking?</strong> Sure.</p>

<p><strong>Does it have metacognition?</strong> No. <del>There isn’t even a mechanism in place for it to reflect on its own behavior, let alone what it “thinks”.</del> Correction: There is a <a href="https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html">mechanism in place for it to rate its own output/behavior</a>, but I still wouldn’t call this “reflection”.</p>

<p><strong>Is this a super cool example of using LMs to generate text?</strong> Absolutely. I always think it’s super cool to see what people do with these models.</p>

<p><strong>Are we close to achieving <a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence">AGI (artificial general intelligence)</a>?</strong> No. Even if it does happen, it probably won’t be in our lifetimes. We have not made the relevant advances to get there. We have a hard enough time getting AI to do <em>more than one task</em> let alone be capable to do everything a dog, dolphin, or donkey can do.</p>

<h2 id="language-models">Language Models</h2>

<p>If you’re unfamiliar with how language models work, it’s a bit like this: You take a ridiculous amount of text (read: the internet) and you run it through a “neural network”. This network is literally just doing a bunch of multi-dimensional multiplications of numbers (called matrix multiplications). You run the data through multiple times, and it eventually abstracts away patterns in the data. This process is called training.</p>

<p><img src="/assets/img/nn.webp" alt="Deep neural network diagram by IBM." />
<em>Deep neural network diagram by IBM. Image from <a href="https://www.ibm.com/cloud/learn/neural-networks">What are Neural Networks?</a>. The “deep” part refers to the hidden layers in the middle.</em></p>

<p>Then when you want to use it, you load up the trained language model into your computer’s memory and give it a prompt. The prompt might be a single word, or it can be a whole question like in the article’s interview. Based on this prompt/input, the LM will give you the most likely text to come next based on the text it trained on. This is generally called running or testing the model.</p>

<center>&mdash;</center>

<p>Working with these models is a bit of an art.</p>

<p><a href="https://openreview.net/pdf?id=rygGQyrFvH">If you’re not careful</a> when you run the model, the language model might give you the most probable word or phrase each time, and you’ll end up getting some very boring text. (Lots of “I don’t know”s.)
But if you go too far the other way—picking the least probable next word or phrase, the language model spits out nonsense!</p>

<p>Training can be tricky to get working right too. 
If you don’t train the network long enough, it doesn’t pick up enough information about the data to really do anything with it. It might not even learn how to spell.</p>

<p>And if you train for too long, the model just memorizes all the data you give it, which might generate some impressive-sounding text because it’s basically copying what a human said verbatim. However, when you give it a prompt is has never seen before, it flounders and gives you gibberish.</p>

<p>With really big language models (like LaMDA), they can <a href="https://arxiv.org/abs/2202.07646">end up memorizing data</a> even when they’re <a href="https://arxiv.org/abs/2205.10770">not trained for too long</a>.</p>

<p>Even if a neural network ends up being really good at one task, it is incredibly difficult to train the network on a new task and <a href="https://link.springer.com/chapter/10.1007/978-3-030-58598-3_28">not</a> <a href="https://www.pnas.org/doi/10.1073/pnas.1611835114">let</a> <a href="https://www.sciencedirect.com/science/article/pii/S1364661317300736">it</a> <a href="https://proceedings.neurips.cc/paper/2017/hash/f708f064faaf32a43e4d3c784e6af9ea-Abstract.html">forget</a> what it learned in the first task. This is called <em>catastrophic forgetting</em>, which probably isn’t that important to know, but I wanted to share since it’s one of my favorite phrases in AI.</p>

<p>All this is to say that neural networks are (1) highly-engineered tools and (2) <em>very loosely inspired</em> by the architecture of the brain, at best.</p>

<h2 id="but-what-is-lamda-specifically">But what is LaMDA, specifically?</h2>

<p>The “really big language models” I’m talking about are called transformers. <a href="https://towardsdatascience.com/transformer-neural-network-step-by-step-breakdown-of-the-beast-b3e096dc857f">Transformer language models</a> such as GPT and BERT (and their “relatives”) have pushed the state-of-the-art of natural language processing (and probably many other computing fields). These neural networks have a special component called <a href="https://www.kaggle.com/code/residentmario/transformer-architecture-self-attention/notebook">“attention”</a>, which basically tells the LM “when you look at a word, pay attention to its context too”.</p>

<p><img src="/assets/img/PLMfamily.jpg" alt="Family of Pretrained Language Models as of a year ago by Xiaozhi Wang and Zhengyan Zhang." />
<em>Family of Pretrained Language Models as of a year ago by Xiaozhi Wang and Zhengyan Zhang. A lot more have come out in the past year. Image from the <a href="https://github.com/thunlp/PLMpapers">PLM papers repo</a>.</em></p>

<p><a href="https://blog.google/technology/ai/lamda/">LaMDA</a> stands for “Language Models for Dialog Applications”. It is a transformer-based language model created by <a href="https://arxiv.org/abs/2201.08239">researchers at Google</a>* that was specifically created for dialog (think chatbot).</p>

<p>*It might be worth noting that Blake Lemoine (the author of the original “interview” article) is not one of the listed authors.</p>

<h2 id="parting-thoughts">Parting Thoughts</h2>

<ul>
  <li>
    <p><strong>Will AI ever be sentient?</strong> It’s not for me to say whether or not AI will ever be sentient, especially as we go deeper into <a href="https://en.wikipedia.org/wiki/Biological_computing">biological computing</a>. I can’t predict the future, but like I said, even if AI were to ever be sentient some day, it will not be during our lifetimes.</p>
  </li>
  <li>
    <p><strong>Should we even be caring about whether or not AI is sentient?</strong> I’d argue no. Just because something isn’t sentient doesn’t mean you shouldn’t care about it. I respect my Roomba’s existence as much as I respect my plants’ or my notebook’s existence. They are all important parts of my environment even if my plants require more care because they are alive.</p>
  </li>
  <li>
    <p><strong>Want to check out more fun interviews with large language models?</strong> Janelle Shane interviews a squirrel, a vacuum, and other things via GPT-3: <a href="https://www.aiweirdness.com/interview-with-a-squirrel/">https://www.aiweirdness.com/interview-with-a-squirrel/</a></p>
  </li>
</ul>


      <div class="page-footer">
        <div class="page-share">
          <div class="share-text">Share:</div>
          <a href="https://twitter.com/intent/tweet?text=No, LaMDA Isn't Sentient&url=https://laramartin.net/2022/06/21/lamda-is-not-sentient.html" title="Share on Twitter" rel="nofollow" target="_blank"><i class="fab fa-twitter"></i> Twitter</a>
          <a href="https://facebook.com/sharer.php?u=https://laramartin.net/2022/06/21/lamda-is-not-sentient.html" title="Share on Facebook" rel="nofollow" target="_blank"><i class="fab fa-facebook"></i> Facebook</a>
          <!--<a 
	  class="mastodon-share-button"
	  data-target="https://laramartin.net/2022/06/21/lamda-is-not-sentient.html"
	  data-name="No, LaMDA Isn't Sentient"
	  data-buttonstyle="btn btn-secondary"
	><i class="fab fa-mastodon"></i>  Mastodon</a>-->
	
        </div>

        <div class="page-tag">
          
            <a href="https://laramartin.net/tags#Language Models" class="tag">&#35; Language Models</a>
          
            <a href="https://laramartin.net/tags#Neural Networks" class="tag">&#35; Neural Networks</a>
          
            <a href="https://laramartin.net/tags#Artificial General Intelligence" class="tag">&#35; Artificial General Intelligence</a>
          
        </div>
      </div>
    </div> <!-- End Wrap Content -->
  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->


<!--
    <div class="modal fade" id="exampleModal" tabindex="-1" role="dialog" aria-labelledby="exampleModalLabel" aria-hidden="true">
      <div class="modal-dialog" role="document">
        <div class="modal-content">
          <div class="modal-header">
            <h5 class="modal-title" id="exampleModalLabel">Instance address</h5>
            <button type="button" class="close" data-dismiss="modal" aria-label="Close">
              <span aria-hidden="true">&times;</span>
            </button>
          </div>
          <div class="modal-body">
            <div class="form-group">
              <label for="msb-address">Enter your instance's address</label>
              <input type="text" class="form-control" id="msb-address" placeholder="https://framapiaf.org">
            </div>
            <div class="form-check">
              <input type="checkbox" class="form-check-input" id="msb-memorize-instance">
              <label class="form-check-label" for="msb-memorize-instance">Memorize my instance</label>
            </div>
          </div>
          <div class="modal-footer">
            <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
            <button id="msb-share" type="button" class="btn btn-primary">Save changes</button>
          </div>
        </div>
      </div>
    </div>

    <img src="https://framaclic.org/h/129I693AIEb9g" alt="">
  </div>-->

</div>

  </div>
  
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', '', 'auto');
  ga('send', 'pageview');
</script> <!-- End Analytics -->

</body>
</html>
